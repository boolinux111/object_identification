{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scenedetect[opencv]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PkMIA4qrZE9",
        "outputId": "9c77431c-0131-4b22-8d20-3a49e4b5e25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scenedetect[opencv]\n",
            "  Downloading scenedetect-0.6.6-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: Click in /usr/local/lib/python3.11/dist-packages (from scenedetect[opencv]) (8.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from scenedetect[opencv]) (2.0.2)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from scenedetect[opencv]) (4.3.8)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from scenedetect[opencv]) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from scenedetect[opencv]) (4.11.0.86)\n",
            "Downloading scenedetect-0.6.6-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scenedetect\n",
            "Successfully installed scenedetect-0.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-5tBygGo5k2",
        "outputId": "c431816c-bfec-4953-8748-5e1fd04b111d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting Scene 1: 0.00s → 30.60s\n",
            "Splitting Scene 2: 30.60s → 39.47s\n",
            "Splitting Scene 3: 39.47s → 49.43s\n",
            "Splitting Scene 4: 49.43s → 59.77s\n",
            "All scenes have been split and saved to: output_scenes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "import cv2\n",
        "from scenedetect.detectors import AdaptiveDetector\n",
        "\n",
        "def detect_scenes_dynamic(input_path,\n",
        "                          motion_threshold: float = 5.0,\n",
        "                          min_skip: int = 0,\n",
        "                          max_skip: int = 5,\n",
        "                          adaptive_threshold: float = 3.0,\n",
        "                          window_width: int = 2,\n",
        "                          min_content_val: float = 15.0):\n",
        "    \"\"\"\n",
        "    모션 변화량에 따라 프레임 스킵을 조정하며 AdaptiveDetector로 씬(컷) 구간을 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        input_path (str): 입력 비디오 경로\n",
        "        motion_threshold (float): 모션 값(motion_val)이 이 이상이면 skip=min_skip\n",
        "        min_skip (int): 모션 클 때 최소 스킵 프레임 수\n",
        "        max_skip (int): 모션 작을 때 최대 스킵 프레임 수\n",
        "        adaptive_threshold (float): AdaptiveDetector adaptive ratio 기준 (높을수록 덜 민감)\n",
        "        window_width (int): adaptive rolling average 윈도우 크기\n",
        "        min_content_val (float): 컷으로 인식되려면 content score 최소값\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[float, float]]: (start_sec, end_sec) 씬 시간 리스트\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(input_path)\n",
        "    if not cap.isOpened():\n",
        "        raise IOError(f\"Cannot open video: {input_path}\")\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    detector = AdaptiveDetector(\n",
        "        adaptive_threshold=adaptive_threshold,\n",
        "        window_width=window_width,\n",
        "        min_content_val=min_content_val,\n",
        "        min_scene_len=1\n",
        "    )\n",
        "\n",
        "    ret, prev_frame = cap.read()\n",
        "    if not ret:\n",
        "        cap.release()\n",
        "        return []\n",
        "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    cut_frame_nums = []\n",
        "    frame_num = 1\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        motion_val = cv2.absdiff(prev_gray, gray).mean()\n",
        "        skip = min_skip if motion_val > motion_threshold else max_skip\n",
        "\n",
        "        cuts = detector.process_frame(frame_num, frame)\n",
        "        if cuts:\n",
        "            cut_frame_nums.extend(cuts)\n",
        "\n",
        "        for _ in range(skip):\n",
        "            if not cap.grab():\n",
        "                break\n",
        "            frame_num += 1\n",
        "\n",
        "        prev_gray = gray\n",
        "        frame_num += 1\n",
        "\n",
        "    cuts = detector.post_process(frame_num)\n",
        "    cut_frame_nums.extend(cuts)\n",
        "    cap.release()\n",
        "\n",
        "    cut_frame_nums = sorted(set(cut_frame_nums))\n",
        "    boundaries = [0] + cut_frame_nums + [total_frames]\n",
        "    scenes = [(boundaries[i]/fps, boundaries[i+1]/fps)\n",
        "              for i in range(len(boundaries)-1)]\n",
        "    return scenes\n",
        "\n",
        "\n",
        "def merge_short_scenes(scenes, min_duration):\n",
        "    \"\"\"\n",
        "    scenes 중 duration이 min_duration 미만인 씬은 이전 씬과 병합합니다.\n",
        "\n",
        "    Args:\n",
        "        scenes (List[Tuple[float, float]]): 원본 씬 리스트\n",
        "        min_duration (float): 최소 씬 길이(초)\n",
        "\n",
        "    Returns:\n",
        "        List[Tuple[float, float]]: 병합 후 씬 리스트\n",
        "    \"\"\"\n",
        "    if not scenes:\n",
        "        return []\n",
        "    merged = [scenes[0]]\n",
        "    for start, end in scenes[1:]:\n",
        "        prev_start, prev_end = merged[-1]\n",
        "        duration = end - start\n",
        "        if duration < min_duration:\n",
        "            # 이전 씬의 끝을 현재 씬의 끝으로 확장\n",
        "            merged[-1] = (prev_start, end)\n",
        "        else:\n",
        "            merged.append((start, end))\n",
        "    return merged\n",
        "\n",
        "\n",
        "def split_scenes(input_path, scenes, output_dir=\"scenes\"):\n",
        "    \"\"\"\n",
        "    FFmpeg를 이용해 씬 구간별로 영상을 분할 저장합니다.\n",
        "    이전 output_dir이 존재하면 삭제 후 새로 생성합니다.\n",
        "    \"\"\"\n",
        "    if os.path.exists(output_dir):\n",
        "        shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for idx, (start, end) in enumerate(scenes, 1):\n",
        "        output_file = os.path.join(output_dir, f\"Scene_{idx}.mp4\")\n",
        "        cmd = [\n",
        "            'ffmpeg', '-y', '-i', input_path,\n",
        "            '-ss', f\"{start:.3f}\", '-to', f\"{end:.3f}\",\n",
        "            '-c', 'copy', output_file\n",
        "        ]\n",
        "        print(f\"Splitting Scene {idx}: {start:.2f}s → {end:.2f}s\")\n",
        "        subprocess.run(cmd, check=True)\n",
        "\n",
        "    print(\"All scenes have been split and saved to:\", output_dir)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    video_file = \"/content/test_video.mp4\"\n",
        "\n",
        "    scenes = detect_scenes_dynamic(\n",
        "        video_file,\n",
        "        motion_threshold=3.0,\n",
        "        min_skip=0,\n",
        "        max_skip=5,\n",
        "        adaptive_threshold=3.2,\n",
        "        window_width=4,\n",
        "        min_content_val=20.0\n",
        "    )\n",
        "    # 영상의 길이에 따라 n초 미만 씬은 병합\n",
        "    scenes = merge_short_scenes(scenes, min_duration=5.0)\n",
        "    split_scenes(video_file, scenes, output_dir=\"output_scenes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output_scenes.zip output_scenes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnMoJec7pCD-",
        "outputId": "b62b2779-de52-4806-bc75-3defe725240f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output_scenes/ (stored 0%)\n",
            "  adding: output_scenes/Scene_5.mp4 (deflated 1%)\n",
            "  adding: output_scenes/Scene_6.mp4 (deflated 1%)\n",
            "  adding: output_scenes/Scene_3.mp4 (deflated 1%)\n",
            "  adding: output_scenes/Scene_2.mp4 (deflated 6%)\n",
            "  adding: output_scenes/Scene_7.mp4 (deflated 0%)\n",
            "  adding: output_scenes/Scene_4.mp4 (deflated 3%)\n",
            "  adding: output_scenes/Scene_1.mp4 (deflated 3%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5nj9rXTlARb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}